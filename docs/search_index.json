[
["index.html", "OCR Tutorial Chapter 1 Prerequisites", " OCR Tutorial Niko Partanen 2020-01-10 Chapter 1 Prerequisites This tutorial is about current OCR technologies, and Niko Partanen’s own practices when building new OCR models. These are not necessarily best practices, but certainly on a road toward that, and all feedback that helps improving the methodology presented here is most welcome. All examples are taken from the National Library of Finland’s Fenno-Ugrica collection. This workshop assumes that the participants are comfortable with installing software from the source, and are used to working on command line. All examples are supposed to be complete and repeatable, and longer command chains are all collected into Chapter ??. "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction This workshop will be built around the materials presented by Partanen and Rießler (2019). That study contained few experiments with training Ocropy models for various languages for which Unified Northern Alphabet was used. The result was that bootstrapping of a new OCR system is extremely fast when the domain is very narrow, i.e. font is known, and there are enough examples of different characters. The study also showed that the system performed comparably well in monolingual and multilingual conditions, indicating that having an OCR system for this writing system, and not one for each language using it, should be a reasonable goal for further work. Example from a book in Selkup In Chapter 3 I go through the main tools we can currently use in OCR. Handwritten text recognition, HTR, is somewhat beyond the capabilities of this software, and in that domain Transkribus system has a very strong position. Thereby that is discussed separately in section 7. Since text recognition is closely connected to layout analysis, that is discussed in 4. I have not personally explored much the field of layout detection, although there certainly is a lot to gain in that front. I would even say that most of our current technical problems relate to layout analysis, more than text recognition itself. In order to start training the models, we need to acquire or create Ground Truth datasets. These are discussed, through various examples, in Chapter 5. In the Chapter 6 I finally get into actual model training, and in the Chapter 8 I provide examples and code for using the models we trained. As will be shown, proofreading Ground Truth and training the model creates a very fast and rewarding loop, where generating more data that improves the model gets increasingly faster. Comments, corrections and additions are more than welcome, either by email (niko.partanen@helsinki.fi), or through GitHub Issues in the project repository. References "],
["tools.html", "Chapter 3 Tools", " Chapter 3 Tools The OCR tools discussed here are: Ocropy Calamari Tesseract I will not discuss Abbyy FineReader at length, besides saying that even though it fits well to casual use, I think it is not really the best choice for creating scientific datasets that are discussed here. In the end of the workshop also Transkribus is discussed. It is a very exciting project that has derived impressive results on handwritten text recognition. It is very recommandable to take a look into it. "],
["layout.html", "Chapter 4 Layout analysis", " Chapter 4 Layout analysis It is important to understand that OCR systems áre primarily about working with the text content itself, traditionally at character level, but at the moment line is the normal minimum unit. The system takes a line and returns the predicted text, but it is an entirely different question how we retrieve these lines. I would even say that OCR itself is much more a solved problem than layout detection. If we have nice lines getting out from them a relatively high accuracy text is very easy. But with complex documents a lots of work is still left in finding all the text areas, lines within them, and how all those connect together into nice running text. Of course the argument can also be made that for variety of purposes it is not even crucial to have the lines and sections connect to one another perfectly. This could be the case, for example, in topic detection tasks etc. It is important not to fall into trap where we think that as something doesn’t work perfectly we cannot use it. Indeed, as the OCR model training does not care about anything beyond an individual line, it is not of any importance there how the lines connect to one another and whether the texts are complete. When we use the OCR model, see section Doing OCR, it is necessary that the lines we get from the line segmentation tool we use are similar to the lines we did the model training with. Thereby it is important to think about the whole pipeline before getting too far. In my experience the Tesseract’s layout analysis tool is very good, and often gives a very sensible result. Also Transkribus has some excellent layout detection capabilities. So running the layout detection in these programs, and extracting the line bounding boxes from the XML returned is a good option. In section Doing OCR I also have an example of how to run the whole pipeline in Python. "],
["ground-truth.html", "Chapter 5 Ground Truth creation 5.1 Examples 5.2 Summary", " Chapter 5 Ground Truth creation The main challenge in creating Ground Truth is that we need a comfortable environment for doing the proofreading, with safety that we know the software used will save the edited file back without any structural changes. Lots of programmers have got the idea to build their own proofreading environment. In practice this is very complicated. Tools that allow editing beyond individual lines usually break something in the XML structure. In principle proofreading tools / environment can be extremely simple, and this is illustrated by Ocropy in the next section. 5.1 Examples We have training data in folders data/batch_1_orig, data/batch_2_orig, data/batch_3_orig, data/batch_4_orig, data/batch_5_orig and data/batch_6_orig. Each batch has 2 pages. We are using Ocropy in this section, so please install Ocropy. This is the starting position: Just scanned images ocropus-nlbin ./example/batch_1_orig/*.png -o ./example/batch_1 Binarized pages This tool can be used to create segmented lines. The system stores somehow information about the line locations, but moving the files around is apparently not a good idea. ocropus-gpageseg ./example/batch_1/*.bin.png Segmented lines Now, let’s pretend we are without any OCR system for this script. Then we would need to add start writing from the scratch. This could be started with the following command: ocropus-gtedit html ./example/batch_1/*/*.png -o ./example/batch_1.html This outputs an HTML file: HTML file appears Empty HTML from Ocropy (has to be edited in Firefox) However, as we have a model from an earlier work, let’s use it for now. ocropus-rpred -Q 4 -m ../unified-northern-alphabet-ocr/models/ocropy/mixed_model.pyrnn.gz ./example/batch_1/*/*.bin.png As we already see from output, the result is sensible: INFO: ./example/batch_1/0001/010003.bin.png:Mikol skolat humus ols. INFO: ./example/batch_1/0001/010007.bin.png:lavs: INFO: ./example/batch_1/0001/010004.bin.png:Skolat ņavram sav oli. Ta savit ņavram, INFO: ./example/batch_1/0001/010008.bin.png:- Ja! tьꜧ-unten INFO: ./example/batch_1/0001/010006.bin.png:varuŋkve eri, at vaꜧte. Uļakꞩi, tau nupьl INFO: ./example/batch_1/0001/010009.bin.png:tuŋkve patev. INFO: ./example/batch_1/0001/010005.bin.png:Mikol at sunsьꜧlas. Mikol nas ļuli, manьr INFO: ./example/batch_1/0001/01000b.bin.png:Sistamьꜧ olen. INFO: ./example/batch_1/0001/01000a.bin.png:Mikol, haniꞩtah- INFO: ./example/batch_1/0001/01000f.bin.png:- Ꞩemen luvtuŋkve eri. INFO: ./example/batch_1/0001/01000e.bin.png:Haniꞩtan hum lavs: INFO: ./example/batch_1/0001/01000c.bin.png:Ꞩemen skolan johtьs. Skolat ņavramьt INFO: ./example/batch_1/0001/010011.bin.png:hurataves. Puŋkane luvtuŋkve haņꞩulaves. INFO: ./example/batch_1/0001/01000d.bin.png:sistamьꜧ oleꜧt. Ꞩemen paŋkьŋьꜧ johtьs. These lines are saved with the images. If we edit the HTML, and the save the file, the edited lines can be saved. This happens with: ocropus-gtedit extract -O ./example/batch_1.html This saves the edited lines with extension .gt.txt. In this point we can do: cat example/batch_1/**/*gt.txt | wc -l &gt; 48 More than enough! Let’s go onward! 5.2 Summary .txt files are collected to the HTML Proofread lines are exported from HTML The wanted outcome is pairs of .bin.png and .gt.txt files These can be used when training the models The idea is that you go now to section @ref(training} about model training, train the first model with what we have, and then the workflow described here is applied to batch_2. "],
["training.html", "Chapter 6 OCR Model training 6.1 Training Calamari 6.2 Training Tesseract", " Chapter 6 OCR Model training Once we have a ground truth dataset, we can start the model training. Most of the time this is relatively simple process, and we just run the training command and tell it where the training files are, and how we want to name the model. The system we use takes care of image preprocessing, which will then be applied also when the model is used. There are few things we usually should keep in mind while training the model: Documenting which training files are used Use Git commit hash in model name? Checkpoint frequency Too high eats your harddisk space Too low is maybe difficult to monitor As the model accuracy can go up and down pretty wildly, it is important to notice when it is in the period of confusion, and use the model before or after that If you have lots of data (10,000–100,000 lines), then let it train for as long as you can Same if you want to release something more publicly Hot take: With small amount of data nothing significant happens after first few hours. If you are in Ground Truth creation loop, iterating the new models fast is a good idea. 6.1 Training Calamari First, install Calamari, something like: pip install calamari_ocr pip install tensorflow Or: git clone https://github.com/Calamari-OCR/calamari conda env create -f environment_master_cpu.yml Calamari model can be trained with a following command: calamari-train --files train/*png --output_model_prefix komi-test- --output_dir models/ --checkpoint_frequency 200 This would save the model into path models/komi-test-000200.... New model would be saved every 200 training steps. The models can be fairly large. With our demo dataset there is the problem that Ocropy and Calamari prefer bit different filenames, so that Calamari doesn’t want .bin.png ending. So let’s collect the files we have into one folder, that is a nice practice anyway. I often do it with Bash like this: mkdir train for gt_line in `ls ./example/*/*/*gt.txt` do bin_png=$(echo $gt_line | sed &#39;s/gt.txt/bin.png/g&#39;) png=$(echo $gt_line | sed &#39;s/gt.txt/png/g&#39;) cp $gt_line ./train/&quot;${gt_line##*/}&quot; cp $bin_png ./train/&quot;${png##*/}&quot; done So we just find all Ground Truth lines, and rename + copy them into directory train. We could, in this point, split it into train and test, but as the data is less than 50 lines, this is maybe a bit early. It is a good idea to use tools like SciKit Learn’s train_test_split in Python, but in this point it isn’t that complicated what we are doing. In the case of our demo dataset, the command would be: calamari-train --files train/*png --output_model_prefix una-batch_1- --output_dir models/ --checkpoint_frequency 200 &gt; Resolving input files &gt; Found 26 files in the dataset &gt; Preloading dataset type DataSetMode.TRAIN with size 26 &gt; Preloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:03&lt;00:00, 8.43it/s] &gt; Computing codec: 100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00&lt;00:00, 21382.73it/s] &gt; CODEC: [&#39;&#39;, &#39; &#39;, &#39;!&#39;, &#39;,&#39;, &#39;-&#39;, &#39;.&#39;, &#39;:&#39;, &#39;A&#39;, &#39;H&#39;, &#39;M&#39;, &#39;O&#39;, &#39;P&#39;, &#39;S&#39;, &#39;T&#39;, &#39;U&#39;, &#39;a&#39;, &#39;e&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;, &#39;k&#39;, &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;, &#39;p&#39;, &#39;r&#39;, &#39;s&#39;, &#39;t&#39;, &#39;u&#39;, &#39;v&#39;, &#39;ļ&#39;, &#39;Ņ&#39;, &#39;ņ&#39;, &#39;ŋ&#39;, &#39;ţ&#39;, &#39;в&#39;, &#39;ь&#39;, &#39;ꜧ&#39;, &#39;Ꞩ&#39;, &#39;ꞩ&#39;] Then the training starts, and what we get it something like: #00000100: loss=103.64814411 ler=1.00000000 dt=1.01209140s PRED: &#39;*,&#39; TRUE: &#39;*Ņavramьt tot joŋhesьt. Uļakꞩi lavs:,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00000200.ckpt&#39; #00000200: loss=88.01333866 ler=1.00000000 dt=1.13691821s PRED: &#39;*,&#39; TRUE: &#39;*Ņavramьt tot joŋhesьt. Uļakꞩi lavs:,&#39; #00000300: loss=84.42394615 ler=1.00000000 dt=12.90764643s PRED: &#39;*,&#39; TRUE: &#39;*vos ols.,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00000400.ckpt&#39; #00000400: loss=66.31870094 ler=0.88571429 dt=2.39815145s PRED: &#39;*pьl ,ꜧьl jteꜧь.,&#39; TRUE: &#39;*tau nupьl lavs, aꜧmьl jemteꜧьn. Ok-,&#39; #00000500: loss=33.71355089 ler=0.78357143 dt=0.87875572s PRED: &#39;*aki kee upьl las,&#39; TRUE: &#39;*Uļakꞩi Ꞩemen nupьl lavs:,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00000600.ckpt&#39; #00000600: loss=17.30537902 ler=0.68943453 dt=0.98521040s PRED: &#39;*use avraьt jŋheꜧt. kol at,&#39; TRUE: &#39;*Pusen ņavramьt joŋheꜧt. Mikol at,&#39; WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.302853). Check your callbacks. #00000700: loss=9.67660141 ler=0.59846268 dt=0.94566187s PRED: &#39;*Uļakꞩi pionerьꜧ oli. au okţarat sart,&#39; TRUE: &#39;*Uļakꞩi pionerьꜧ oli. Tau okţaвrat sart,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00000800.ckpt&#39; #00000800: loss=6.00772715 ler=0.52365484 dt=0.86985343s PRED: &#39;*pьriꞩiꜧ oli.,&#39; TRUE: &#39;*pьriꞩiꜧ oli.,&#39; #00000900: loss=4.19488548 ler=0.47200692 dt=0.79613184s PRED: &#39;*Hohsan ht-lajen, joŋhuŋkve tьꜧ-,&#39; TRUE: &#39;*- Hohsan hot-lajen, joŋhuŋkve tьꜧ-,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00001000.ckpt&#39; #00001000: loss=2.85367827 ler=0.42480623 dt=1.01420514s PRED: &#39;*harteꜧt!,&#39; TRUE: &#39;*harteꜧt!,&#39; #00001100: loss=2.35952931 ler=0.39628849 dt=1.01120380s PRED: &#39;*ꞩopitel.,&#39; TRUE: &#39;*ꞩopiteln.,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00001200.ckpt&#39; #00001200: loss=1.79808081 ler=0.36326445 dt=0.93737005s PRED: &#39;*jajen.,&#39; TRUE: &#39;*jajen.,&#39; #00001300: loss=1.41390861 ler=0.33532103 dt=1.03504477s PRED: &#39;*Ņavramьten Sano joŋhuŋkve untuves.,&#39; TRUE: &#39;*Ņavramьten Sano joŋhuŋkve untuves.,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00001400.ckpt&#39; #00001400: loss=1.39289295 ler=0.31136953 dt=1.04986981s PRED: &#39;*Ņavramьt Uļakꞩi huntleꜧt.,&#39; TRUE: &#39;*Ņavramьt Uļakꞩi huntleꜧt.,&#39; #00001500: loss=0.89948882 ler=0.29061156 dt=1.21357172s PRED: &#39;*vos ols.,&#39; TRUE: &#39;*vos ols.,&#39; Storing checkpoint to &#39;/Users/niko/github/ocr-tutorial/data/models/una-batch_1-00001600.ckpt&#39; #00001600: loss=0.80192822 ler=0.27423405 dt=1.04396018s PRED: &#39;*Semel part hot-osꜧeln. Hasne rakt,&#39; TRUE: &#39;*- Semel part hot-osꜧeln. Hasne rakt,&#39; #00001700: loss=0.76085947 ler=0.26146398 dt=1.28815659s PRED: &#39;*tau nupьl lavs,aꜧmmьl jemteꜧьn. Ok-,&#39; TRUE: &#39;*tau nupьl lavs, aꜧmьl jemteꜧьn. Ok-,&#39; Of course the system is only repeating the same small number of lines, so it eventually just learns them. After having it run 2000 steps we stop, and let’s test that model: calamari-predict --checkpoint ./models/una-batch_1-00002000.ckpt.json --files ./mixed/*.png Then we test it: calamari-eval --gt ./mixed/*.gt.txt What we get is: Resolving files Loading GT: 100%|███████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:03&lt;00:00, 250.50it/s] Loading Prediction: 100%|███████████████████████████████████████████████████████████████████████████████| 800/800 [00:02&lt;00:00, 329.61it/s] Evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████| 800/800 [00:01&lt;00:00, 552.01it/s] Evaluation result ================= Got mean normalized label error rate of 24.43% (5495 errs, 22494 total chars, 5585 sync errs) GT PRED COUNT PERCENT {ə} {a} 237 4.24% {d} {ol} 195 6.98% {m} {n} 153 2.74% {n} {} 133 2.38% {m} {nn} 98 3.51% {w} {v} 90 1.61% {æ} {ae} 85 3.04% {q} {op} 82 2.94% {ļ} {} 80 1.43% {c} {o} 73 1.31% The remaining but hidden errors make up 69.81% Error rate of 24.43% means that every fourth character needs to be fixed, but that is already much better than what we had in the beginning. 6.2 Training Tesseract Training Tesseract can be a bit intimidating process. In last years many improvements have been done, and at the moment training is possible on both Linux and Mac. There is, additionally, tessmake project that very conveniently wraps the training process into a Makefile. make training MODEL_NAME=komi-test GROUND_TRUTH_DIR=train/ If you want to change the parameters, play around with the Makefile. This gives a very good Tesseract model if you have enough data. The models, to be foundable for Tesseract, have to be in so called tessdata directory. This can be also specified when using Tesseract by specifying --tessdata-dir. "],
["htr.html", "Chapter 7 Handwritten text recognition", " Chapter 7 Handwritten text recognition At the moment Transkribus project offers the best platform for handwritten text recognition, as well as for lots of OCR related tasks. Training also OCR models with the Transkribus system seems to work extremely, even ridiculously, well, so that is certainly worth playing around. One example of how collections edited in Transkribus can be made available can be seen in this interface for National Archives of Finland’s data. "],
["using-models.html", "Chapter 8 Using OCR models 8.1 Using Tesseract 8.2 Using Calamari", " Chapter 8 Using OCR models In this section we go through with practical examples how OCR models can be used.chr 8.1 Using Tesseract Tesseract… R bindings… Python bindings… 8.2 Using Calamari Calamari… "],
["references.html", "References", " References "]
]
